augmented_predictions <- predict_survival(augmented_model, data, times)
# Create risk groups based on deciles of predictions
data$base_risk_group <- ntile(base_predictions, 10)
base_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix, data = data, x=T)
summary(base_model)
fit1<-survfit(base_model,newdata=data)
data$risk_base<-1-as.numeric(summary(fit1,times=5)$surv)
augmented_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix + log.lvmi, data = data, x=T)
fit2<-survfit(augmented_model,newdata=data)
data$risk_augmented<-1-as.numeric(summary(fit2,times=5)$surv)
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(time.y, event==1)~1,
data=htrap,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(readr)
library(survival)
library(pROC)
library(survminer)
library(randomForestSRC)
library(gbm)
library(utils) #For not having to upload the txt each time
base_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix, data = data, x=T)
summary(base_model)
fit1<-survfit(base_model,newdata=data)
data$risk_base<-1-as.numeric(summary(fit1,times=5)$surv)
augmented_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix + log.lvmi, data = data, x=T)
fit2<-survfit(augmented_model,newdata=data)
data$risk_augmented<-1-as.numeric(summary(fit2,times=5)$surv)
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(time.y, event==1)~1,
data=htrap,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
library(riskRegression)
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(time.y, event==1)~1,
data=htrap,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(time.y, event==1)~1,
data=data,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
head(data)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(readr)
library(survival)
library(pROC)
library(survminer)
library(randomForestSRC)
library(gbm)
library(utils) #For not having to upload the txt each time
#setwd('~/Desktop/Data Science/Data Science Lab in Medicine/Big Data in Health Care/')
url <- "https://raw.githubusercontent.com/darthgween/BigDataInHealthCareProject/main/heart.valve.txt?token=GHSAT0AAAAAACR3GYSXO5Z3ARKVQY2S6SYSZRYZQWA"
data <- read.table(url, header = TRUE)
head(data)
dim(data)
str(data)
summary(data)
ggplot(data, aes(x = age)) +
geom_histogram(binwidth = 5, fill = "lightblue", color = "black") +
ggtitle("Distribuzione dell'età") +
xlab("Età") +
ylab("Frequenza")
cor_matrix <- cor(data, use = "complete.obs")
print(cor_matrix)
if (!require(corrplot)) {
install.packages("corrplot")
library(corrplot)
}
corrplot(cor_matrix, method = "circle")
data$sex <- factor(data$sex, levels = c(0, 1), labels = c("Male", "Female"))
data$con.cabg <- factor(data$con.cabg, levels = c(0, 1), labels = c("No", "Yes"))
data$lv <- factor(data$lv, levels = c(1, 2, 3), labels = c("High", "Moderate", "Low"))
data$sten.reg.mix <- factor(data$sten.reg.mix, levels = c(1, 2, 3), labels = c("Stenosis", "Regurgitation", "Mixed"))
ggplot(data, aes(x = factor(status), y = log.lvmi, fill = factor(status))) +
geom_boxplot() +
ggtitle("Boxplot of log.lvmi for Status") +
xlab("Status") +
ylab("log.lvmi") +
scale_fill_discrete(name = "Status")
ggplot(data, aes(x = age, y = log.lvmi)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", color = "red", se = FALSE) +
ggtitle("Scatter Plot: età vs log.lvmi") +
xlab("Età") +
ylab("log.lvmi")
# The outcome variable is a survival object created with the time to event (fuyrs) and status indicator (status)
surv_obj <- Surv(data$fuyrs, data$status)
# Perform Cox regression for each predictor
# Excluding paz.id from the analysis as it's an identifier, not a predictor
variables <- c("log.lvmi", "sex", "age", "con.cabg", "creat", "lv", "sten.reg.mix")
# Store results in a list for easy access
univariate_models <- list()
for (var in variables) {
# Formula to dynamically create the regression model
formula <- as.formula(paste("surv_obj ~", var))
# Fit the Cox model
model <- coxph(formula, data = data)
# Print the summary of the model
print(summary(model))
# Store the model in the list
univariate_models[[var]] <- model
}
univariate_models[["log.lvmi"]]
univariate_models[["sex"]]
univariate_models[["age"]]
univariate_models[["con.cabg"]]
univariate_models[["creat"]]
univariate_models[["lv"]]
univariate_models[["sten.reg.mix"]]
base_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix, data = data)
summary(base_model)
# Evaluate the proportional hazards assumption using cox.zph function
# This function performs a test of proportional hazards based on the scaled Schoenfeld residuals
ph_test <- cox.zph(base_model)
# Plotting the residuals to visually inspect any trend indicating non-proportionality
plot(ph_test)  # Multiple plots if more than one covariate; assess each plot for trends over time
# Output the global test of proportional hazards from cox.zph
print(ph_test) # This will display the test statistics and p-values for each covariate
# Check the linearity of continuous variables using Martingale residuals from a null model
null_model <- coxph(Surv(fuyrs, status) ~ 1, data = data) # Null model with no covariates
# Selecting continuous variables to check for non-linearity
continuous_vars <- c("age", "creat")
# Plot Martingale residuals against each continuous variable
for(var in continuous_vars) {
# Plot residuals against continuous variables
plot(data[[var]], residuals(null_model, type = "martingale"), xlab = var, ylab = "Martingale residuals", main = paste("Linearity Check for", var))
abline(h = 0, col = "red")  # Horizontal line at zero to aid in visual assessment
}
augmented_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix + log.lvmi, data = data)
summary(augmented_model)
# Evaluate the proportional hazards assumption using cox.zph function
# This function performs a test of proportional hazards based on the scaled Schoenfeld residuals
ph_test_augmented <- cox.zph(augmented_model)
# Plotting the residuals to visually inspect any trend indicating non-proportionality
plot(ph_test_augmented)  # Multiple plots if more than one covariate; assess each plot for trends over time
# Output the global test of proportional hazards from cox.zph
print(ph_test_augmented) # This will display the test statistics and p-values for each covariate
# Selecting continuous variables to check for non-linearity
continuous_vars_augmented <- c("age", "creat", "log.lvmi")  # Now including log.lvmi
# Plot Martingale residuals against each continuous variable
for(var in continuous_vars_augmented) {
# Plot residuals against continuous variables
plot(data[[var]], residuals(null_model, type = "martingale"), xlab = var, ylab = "Martingale residuals", main = paste("Linearity Check for", var))
abline(h = 0, col = "red")  # Horizontal line at zero to aid in visual assessment
}
augmented_model_poly <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix + poly(log.lvmi, 3), data = data)
summary(augmented_model_poly)
# Evaluate the proportional hazards assumption using the cox.zph function
# This function tests the proportional hazards assumption based on the scaled Schoenfeld residuals
ph_test_2 <- cox.zph(augmented_model_poly)
# Plotting the residuals to visually inspect any trend indicating non-proportionality
plot(ph_test_2)  # This generates multiple plots if there are multiple covariates
# Print the global test of proportional hazards
print(ph_test_2) # Displays test statistics and p-values for each covariate
# Plot Martingale residuals against each continuous variable
for(var in continuous_vars_augmented) {
# Plot residuals against continuous variables
plot(data[[var]], residuals(null_model, type = "martingale"), xlab = var, ylab = "Martingale residuals", main = paste("Linearity Check for", var))
abline(h = 0, col = "red")  # Horizontal line at zero to aid in visual assessment
}
base_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix, data = data, x=T)
summary(base_model)
fit1<-survfit(base_model,newdata=data)
data$risk_base<-1-as.numeric(summary(fit1,times=5)$surv)
augmented_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix + log.lvmi, data = data, x=T)
fit2<-survfit(augmented_model,newdata=data)
data$risk_augmented<-1-as.numeric(summary(fit2,times=5)$surv)
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(time.y, event==1)~1,
data=data,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
# TRYING CALIBRATION PLOTS
library(survival)
library(rms)
library(ggplot2)
install.packages('survAUC')
library(survAUC)
library(rms)
# Create a calibration plot
calib <- calibrate(base_model, method = "boot", B = 100)
install.packages("survAUC")
# TRYING CALIBRATION PLOTS
library(survival)
library(rms)
library(ggplot2)
install.packages('survAUC')
library(survAUC)
library(rms)
# Create a calibration plot
calib <- calibrate(base_model, method = "boot", B = 100)
install.packages("survAUC")
# Load necessary libraries
#install.packages("rms")
library(rms)
#install.packages("survival")
library(survival)
# Assuming data is your dataframe with the relevant variables
# Example dataset
# data <- data.frame(fuyrs = ..., status = ..., sex = ..., age = ..., con.cabg = ..., creat = ..., lv = ..., sten.reg.mix = ...)
# Set up the data distribution for rms package
dd <- datadist(heart.valve)
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status==1)~1,
data=data,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(readr)
library(survival)
library(pROC)
library(survminer)
library(randomForestSRC)
library(gbm)
library(utils) #For not having to upload the txt each time
library(riskRegression) #For performance indicators
base_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix, data = data, x=T)
summary(base_model)
fit1<-survfit(base_model,newdata=data)
data$risk_base<-1-as.numeric(summary(fit1,times=5)$surv)
augmented_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix + log.lvmi, data = data, x=T)
fit2<-survfit(augmented_model,newdata=data)
data$risk_augmented<-1-as.numeric(summary(fit2,times=5)$surv)
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status==1)~1,
data=data,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
plotROC(score,times=1,cens.method="local")
title(main="time‐dependent ROC at 1 years")
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status==1)~1,
data=data,conf.int=T,
times=seq(1,10,1),
plots=c("calibration","ROC"))
plotROC(score,times=1,cens.method="local")
title(main="time‐dependent ROC at 1 years")
augmented_model <- coxph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix + log.lvmi, data = data, x=T)
fit2<-survfit(augmented_model,newdata=data)
data$risk_augmented<-1-as.numeric(summary(fit2,times=5)$surv)
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(1,10,1),
plots=c("calibration","ROC"))
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(1,10,1),
plots=c("calibration","ROC"))
plotROC(score,times=1,cens.method="local")
title(main="time‐dependent ROC at 1 years")
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
plotROC(score,times=1,cens.method="local")
title(main="time‐dependent ROC at 1 years")
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(1,3,1),
plots=c("calibration","ROC"))
plotROC(score,times=1,cens.method="local")
title(main="time‐dependent ROC at 1 years")
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(2,3,2),
plots=c("calibration","ROC"))
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(2,3,2),
plots=c("calibration","ROC"))
plotROC(score,times=1,cens.method="local")
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
plotROC(score,times=1,cens.method="local")
title(main="time‐dependent ROC at 1 years")
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
plotROC(score,times=5,cens.method="local")
title(main="time‐dependent ROC at 1 years")
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(1,10,1),
plots=c("calibration","ROC"))
plotROC(score,times=10,cens.method="local")
title(main="time‐dependent ROC at 1 years")
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(1,10,1),
plots=c("calibration","ROC"))
plotROC(score,times=5,cens.method="local")
title(main="time‐dependent ROC at 1 years")
score <- Score(list("Base"=base_model,"Augmented"=augmented_model),
formula=Surv(fuyrs, status)~1,
data=data,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
plotROC(score,times=5,cens.method="local")
title(main="time‐dependent ROC at 1 years")
# Assuming `time` is your follow-up time and `status` is your event indicator:
# Calculate Brier score and AUC for the base model
score_base <- Score(list(survival = Surv(data$time, data$status)),
formula = ~ risk_base,
data = data,
times = c(1, 2, 3), # specify the times at which to calculate the scores
cause = 1,
estimator = "brier",
summary = "auc")
# Assuming `time` is your follow-up time and `status` is your event indicator:
# Calculate Brier score and AUC for the base model
score_base <- Score(list(survival = Surv(data$fuyrs, data$status)),
formula = ~ risk_base,
data = data,
times = c(1, 2, 3), # specify the times at which to calculate the scores
cause = 1,
estimator = "brier",
summary = "auc")
# Evaluate the performance of the models
# For calibration, discrimination, and Net Benefit, you can use specific methods like Kaplan-Meier curves, calibration plots, concordance index (C-index), and decision curve analysis (DCA).
# Example of Kaplan-Meier curves for the base model
ggsurvplot(survfit(base_model), data = data, risk.table = TRUE)
# Load necessary libraries
#install.packages("rms")
library(rms)
#install.packages("survival")
library(survival)
# Assuming data is your dataframe with the relevant variables
# Example dataset
# data <- data.frame(fuyrs = ..., status = ..., sex = ..., age = ..., con.cabg = ..., creat = ..., lv = ..., sten.reg.mix = ...)
# Set up the data distribution for rms package
dd <- datadist(heart.valve)
# Load necessary libraries
#install.packages("rms")
library(rms)
#install.packages("survival")
library(survival)
# Assuming data is your dataframe with the relevant variables
# Example dataset
# data <- data.frame(fuyrs = ..., status = ..., sex = ..., age = ..., con.cabg = ..., creat = ..., lv = ..., sten.reg.mix = ...)
# Set up the data distribution for rms package
dd <- datadist(data)
options(datadist = 'dd')
# Fit the Cox proportional hazards model using cph from rms package
cph_model <- cph(Surv(fuyrs, status) ~ sex + age + con.cabg + creat + lv + sten.reg.mix, data = data, x = TRUE, y = TRUE, surv = TRUE)
# Calibrate the model
calib <- calibrate(cph_model, method = "boot", B = 200, u = 5)
# Plot the calibration curve
plot(calib, xlim = c(0, 1), ylim = c(0, 1), xlab = "Predicted Probability", ylab = "Observed Probability", main = "Calibration Plot")
# TRYING CALIBRATION PLOTS
library(survival)
library(rms)
library(ggplot2)
install.packages('survAUC')
library(survAUC)
library(rms)
# Create a calibration plot
calib <- calibrate(base_model, method = "boot", B = 100)
install.packages("survAUC")
fit<-survfit(Surv(fuyrs, status) ~ 1, data)
library(survival)
library(rms)
library(ggplot2)
install.packages('survAUC')
library(survAUC)
library(rms)
fit<-survfit(Surv(fuyrs, status) ~ 1, data)
plot(fit, xlab='Years since transplant', ylab='Survival probability')
install.packages("survAUC")
#### Test Proportional Hazards - Martingale and Schoenfeld
# Function to plot Martingale residuals for continuous variables - FUNCTIONAL FORM
plot_martingale <- function(variable) {
# Compute residuals
martingale_res <- residuals(base_model, type = "martingale")
# Create a data frame for plotting
plot_data <- data.frame(Variable = data[[variable]], Residuals = martingale_res)
# Plot
ggplot(plot_data, aes(x = Variable, y = Residuals)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "loess", color = "red") +
labs(title = paste("Martingale residuals vs", variable),
x = variable,
y = "Martingale Residuals")
}
# Plot Martingale residuals for 'age' and 'creat'- FUNCTIONAL FORM
plot_martingale("age")
# Prediction of event risk at a fixed time-point (e.g., 5 years) for three subjects
# You can predict the survival probability for specific subjects using the predict function.
predict(base_model, newdata = data.frame(sex = c(0, 1, 0), age = c(50, 60, 70), con.cabg = c(1, 0, 1), creat = c(1.2, 1.5, 1.3), lv = c(2, 3, 1), sten.reg.mix = c(1, 3, 2), log.lvmi = c(2.5, 3.0, 2.7)), type = "risk", times = 5)
# Example of Kaplan-Meier curves for the augmented model
ggsurvplot(survfit(augmented_model), data = data, risk.table = TRUE)
# Predictions for augmented model
predict(augmented_model, newdata = data.frame(sex = c(0, 1, 0), age = c(50, 60, 80), con.cabg = c(1, 0, 1), creat = c(1.2, 1.5, 1.3), lv = c(2, 3, 1), sten.reg.mix = c(1, 3, 2), log.lvmi = c(2.5, 3.0, 2.7)), type = "risk", times = 5)
rsf_pred <- predict(rsf_model, data)$predicted
#Risk quantiles of 1
q1 <- quantile(data$risk_base,  probs = seq(0.1, 0.9, 0.1))
# Risk classes of 1:
riskclass1 <- ifelse(data$risk_base < q1[1], 1,
ifelse(data$risk_base < q1[2], 2,
ifelse(data$risk_base < q1[3], 3,
ifelse(data$risk_base < q1[4], 4,
ifelse(data$risk_base < q1[5], 5,
ifelse(data$risk_base < q1[6], 6,
ifelse(data$risk_base < q1[7], 7,
ifelse(data$risk_base < q1[8], 8,
ifelse(data$risk_base < q1[9], 9,
10)))))))))
# Observed proportion of events in risk classes of 1:
obsclass1 <- c()
for (i in 1:10) {
group <- i
ratio <- sum(data$status[riskclass1 == group]) / sum(riskclass1 == group)
obsclass1 <- c(obsclass1, ratio)
}
# Average predicted risk in classes of 1:
meanriskclass1 <- c()
for (i in 1:10) {
group <- i
meanrisk <- mean(data$risk_base[riskclass1 == group])
meanriskclass1 <- c(meanriskclass1, meanrisk)
}
#Risk quantiles of 2
q2 <- quantile(data$risk_augmented,  probs = seq(0.1, 0.9, 0.1))
# Risk classes of 1:
riskclass2 <- ifelse(data$risk_augmented < q2[1], 1,
ifelse(data$risk_augmented < q2[2], 2,
ifelse(data$risk_augmented < q2[3], 3,
ifelse(data$risk_augmented < q2[4], 4,
ifelse(data$risk_augmented < q2[5], 5,
ifelse(data$risk_augmented < q2[6], 6,
ifelse(data$risk_augmented < q2[7], 7,
ifelse(data$risk_augmented < q2[8], 8,
ifelse(data$risk_augmented < q2[9], 9,
10)))))))))
# Observed proportion of events in risk classes of 2:
obsclass2 <- c()
for (i in 1:10) {
group <- i
ratio <- sum(data$status[riskclass2 == group]) / sum(riskclass2 == group)
obsclass2 <- c(obsclass2, ratio)
}
# Average predicted risk in classes of 2:
meanriskclass2 <- c()
for (i in 1:10) {
group <- i
meanrisk <- mean(data$risk_augmented[riskclass2 == group])
meanriskclass2 <- c(meanriskclass2, meanrisk)
}
# Calibration plot
par(mar=c(5,5,1,1))
plot(meanriskclass1, obsclass1, main = '', pch = 1, xlim = c(0,1), cex = 1.5,
ylim = c(0,1), lwd = 3, ylab = 'Observed event rate', cex.lab = 1.7, cex.axis = 1.7,
xlab = 'Average risk within decile', xaxt = "n", yaxt = "n", frame = F)
axis(2, at = c(0,0.2,0.4,0.6,0.8,1), labels = NA, pos = 0)
axis(2, at = c(0,0.2,0.4,0.6,0.8,1), labels = c(0,0.2,0.4,0.6,0.8,1), cex.axis = 1.7, pos = 0)
axis(1, at = c(0,0.2,0.4,0.6,0.8,1), labels = c(0,0.2,0.4,0.6,0.8,1), cex.axis = 1.7, pos = 0)
points(meanriskclass2, obsclass2, lwd = 3, pch = 2, cex = 1.5)
lines(c(0, 1), c(0, 1), lty = 2, lwd = 2)
lines(c(0,1), c(1,1), lty = 1)
lines(c(1,1), c(0,1), lty = 1)
legend(x = 0, y = 1, c("Base Model Risk","Augmented Model Risk"), lwd = c(3, 3), pch = c(1, 2),
bty = 'n', cex = 1.8, lty = c(NA,NA))
# indicator of death within 5 year
data$status.5y<-ifelse(data$fuyrs<=5,1,0)
# Brier Score
(BS_base <- mean((data$status.5y - data$risk_base) ^ 2))
(BS_augmented <- mean((data$status.5y - data$risk_augmented) ^ 2))
BS_basesc  <- mean(data$risk_base*(1-data$risk_base))
BS_augmentedsc <- mean(data$risk_augmented*(1-data$risk_augmented))
BS_base-BS_basesc
BS_augmented-BS_augmentedsc
roc1<-roc(data$status.5y, data$risk_base)
score<- Score(list("model1"=base_model_1,"model2"=augmented_model_2),
formula=Surv(fuyrs, status==1)~1,
data,conf.int=T,
times=seq(1,5,1),
plots=c("calibration","ROC"))
library(dcurves)
dca(Surv(fuyrs, status==1) ~ risk_base + risk_augmented, data, time = 5)
# Function to run univariate Cox model and return summary
run_cox_model <- function(variable) {
formula <- as.formula(paste("Surv(fuyrs, status) ~", variable))
model <- coxph(formula, data = data)
summary(model)
}
# List of variables to test
variables <- c("log.lvmi", "sex", "age", "con.cabg", "creat", "lv", "sten.reg.mix")
# Apply the function to each variable and store results
model_results <- lapply(variables, run_cox_model)
